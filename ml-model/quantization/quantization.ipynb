{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,801,540\n",
      "Trainable params: 1,213,828\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model (best saved one)\n",
    "with open('./model/finalproject_model.json', 'r') as json_file:\n",
    "    json_savedModel= json_file.read()\n",
    "    \n",
    "# load the model  \n",
    "model = tf.keras.models.model_from_json(json_savedModel)\n",
    "model.load_weights('./model/finalproject_weights.h5')\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics= [\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f74b4402e50>,\n",
       " <keras.engine.functional.Functional at 0x7f7558231eb0>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7f74b4402910>,\n",
       " <keras.layers.core.dense.Dense at 0x7f74b422a520>,\n",
       " <keras.layers.core.dropout.Dropout at 0x7f74b41ce100>,\n",
       " <keras.layers.core.dense.Dense at 0x7f74b41f1eb0>,\n",
       " <keras.layers.core.dropout.Dropout at 0x7f74b41f1b20>,\n",
       " <keras.layers.core.dense.Dense at 0x7f74b41a1460>,\n",
       " <keras.layers.core.dense.Dense at 0x7f74b41a5c10>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the base_model from the rest of the model\n",
    "base_model = model.layers[1]\n",
    "rest_of_model = model.layers[2:]\n",
    "\n",
    "# Create a quantization-aware model for the rest of the model\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# Manually build the model or infer the input shape automatically\n",
    "rest_of_model = tf.keras.Sequential(rest_of_model)\n",
    "rest_of_model.build(input_shape=(None, 8, 8, 2048))\n",
    "\n",
    "quantized_rest_of_model = quantize_model(rest_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " sequential_13 (Sequential)  (None, 4)                 1213856   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,801,568\n",
      "Trainable params: 1,213,828\n",
      "Non-trainable params: 23,587,740\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Combine the quantized rest_of_model with the base_model\n",
    "quantized_model = tf.keras.Sequential([model.layers[0], base_model, quantized_rest_of_model])\n",
    "\n",
    "quantized_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "quantized_model.build(input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2814 files belonging to 4 classes.\n",
      "\n",
      "    Total Batches: 88,\n",
      "    Training Batches: 66,\n",
      "    Testing Batches: 8,\n",
      "    Validation Batches: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../datasets-4\",\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "total_batches = len(dataset)\n",
    "train_size = int(0.75 * total_batches)\n",
    "test_size = int(0.10 * total_batches)\n",
    "val_size = total_batches - train_size - test_size\n",
    "\n",
    "print(f\"\"\"\n",
    "    Total Batches: {total_batches},\n",
    "    Training Batches: {train_size},\n",
    "    Testing Batches: {test_size},\n",
    "    Validation Batches: {val_size}\n",
    "\"\"\")\n",
    "\n",
    "train_ds = dataset.take(train_size) # used for training data\n",
    "test_ds = dataset.skip(train_size).take(test_size) # final evaluation will be done on this model\n",
    "val_ds = dataset.skip(train_size + test_size).take(val_size) # used to tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(2000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(2000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 09:47:34.264523: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 24 of 2000\n",
      "2023-05-19 09:47:44.398488: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 58 of 2000\n",
      "2023-05-19 09:47:47.325555: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-05-19 09:47:48.441974: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n",
      "2023-05-19 09:47:49.694945: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/66 [..............................] - ETA: 33:26 - loss: 0.1154 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 09:47:52.394671: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-19 09:47:52.394708: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-19 09:47:52.447569: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-05-19 09:47:52.447599: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 44s 206ms/step - loss: 0.1401 - accuracy: 0.9432\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.1323 - accuracy: 0.9451\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.1224 - accuracy: 0.9569\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.1089 - accuracy: 0.9593\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.1133 - accuracy: 0.9574\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.1107 - accuracy: 0.9635\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.1042 - accuracy: 0.9574\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.1026 - accuracy: 0.9621\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 0.0924 - accuracy: 0.9635\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 14s 208ms/step - loss: 0.0849 - accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f749d5412b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model.fit(train_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 09:54:21.476393: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1 of 2000\n",
      "2023-05-19 09:54:21.755415: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 2 of 2000\n",
      "2023-05-19 09:54:23.889349: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 29s 212ms/step - loss: 0.1112 - accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "scores = quantized_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 09:55:52.563207: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses, dense_1_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe5yls_q9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe5yls_q9/assets\n",
      "/home/totoro/.local/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-05-19 09:56:12.002780: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-05-19 09:56:12.002812: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2023-05-19 09:56:12.007560: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpe5yls_q9\n",
      "2023-05-19 09:56:12.042761: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2023-05-19 09:56:12.042797: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpe5yls_q9\n",
      "2023-05-19 09:56:12.171055: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-05-19 09:56:12.819567: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpe5yls_q9\n",
      "2023-05-19 09:56:13.060715: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1054051 microseconds.\n",
      "2023-05-19 09:56:13.598854: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "# Convert the quantized model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized TFLite model to a file\n",
    "with open('quantized_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
